#!/usr/bin/ruby
%w[rubygems nokogiri curb uri pp].each { |m| require m }

# TODO: - REWRITE so it's like 'shuffle'. ("grab audio http://site.com/stuff/ /d/mp3")
#       - use progress bar
#       - lightbar to flag files you want to get (w/ "select all"/"select none"/"invert")
#       - let user filter by regexp
#       - resume ("-w" or "-c" to use curl or wget, "-r" to use internal resume)
#       - "-n" mode (show links only)
#       - 


class Grabber
  
  HTTP_STATUS_CODES = {
    000 => "Incomplete/Undefined error",
    201 => "Created",
    202 => "Accepted",
    203 => "Partial Information",
    204 => "Page does not contain any information",
    204 => "No response",
    206 => "Only partial content delivered",
    300 => "Page redirected",
    301 => "Permanent URL relocation",
    302 => "Temporary URL relocation",
    303 => "Temporary relocation method and URL",
    304 => "Document not modified",
    400 => "Bad request (syntax)",
    401 => "Unauthorized access (requires authentication)",
    402 => "Access forbidden (payment required)",
    403 => "Forbidden",
    404 => "URL not found",
    405 => "Method not Allowed (Most likely the result of a corrupt CGI script)",
    408 => "Request time-out",
    500 => "Internet server error",
    501 => "Functionality not implemented",
    502 => "Bad gateway",
    503 => "Service unavailable",
  }
  
  OKAY_CODES = [200, 403, 405]
  
  def initialize(verbose=false, depth=0)
    @easy = Curl::Easy.new do |c|
      c.headers["User-Agent"] = "Curl/Ruby"
      c.encoding = "gzip,deflate"
  
      c.verbose = verbose
     
      c.follow_location = true
      c.max_redirects = depth
  
      c.enable_cookies = true
    end
  end

  def read(url)
    @easy.url = url
    @easy.perform
    
    @easy.body_str
  end
  
  def download(url, save_to)
    #@easy.url = url
    first_time = nil
    last_bytes = nil
    Curl::Easy.download(url, save_to) do |easy|
      easy.on_progress do |dl_total, dl_now, ul_total, ul_now|
        
        speed = nil
        
        first_time ||= Time.now
        
        if first_time        
          elapsed = Time.now - first_time
          transferred = dl_now
          speed = (transferred/elapsed).to_i 
        end
        
        percent   = "%0.2f%" % (dl_now/dl_total*100)
        percent   = "%#{"100.00%".size}s" % percent
        total     = dl_total.to_i.to_s
        recvd     = "%#{total.size}s" % dl_now.to_i.to_s
        
        print "\r"
        print "  |_ #{percent} - #{recvd} / #{total} bytes (#{speed} bytes/sec}"
        STDOUT.flush
        last_time = Time.now
        last_bytes = dl_now
        true
      end
    end
    
    puts
    return
    
    File.open(save_to, "wb") do |output|
      old_on_body = @easy.on_body do |data| 
        result = old_on_body ? old_on_body.call(data) : data.length
        output << data if result == data.length
        result
      end
      
      @easy.perform
    end        
  end    
  
  def save(url, dest)
    if File.directory?(dest)
      save_to = File.join( dest, filename_from_url(url) )
    elsif File.exists?(dest)
      # TODO: Resume?
      raise "Error: #{dest} already exists."
    else
      save_to = dest
    end
    
    puts %{- "#{url}" -> "#{save_to}"...}
    # @easy.on_progress { |dl_total, dl_now, ul_total, ul_now| ... }
    
    download(url, save_to) 
    puts
  end
  
  def graball(base, dest=".", prompt=true, depth=0)
    puts "* Reading: #{base}..."
    doc = Nokogiri::HTML( read base )
    
    puts "* Media links:"
    links = doc.search("a").map do |a|
      link = a["href"]
      media_url?(link) ? link : nil
    end.compact
    
    links.each do |link|
      puts "  |_ #{link}"
    end
    
 
    loop do
      puts
      print "* Save all? [Y/n] "
    
      response = $stdin.gets.strip.downcase
      
      case response
        when "y", ""
          puts "  |_ saving..."
          links.each do |link|
            save(absolute_url(base, link), dest)
          end
          break
        when "n"
          puts "  |_ aborting..."
          break
      end
    end
    
  end
    
private

  def absolute_url(base, relative)
    if relative =~ /^http/
      relative
    else
      URI.join(base, relative).to_s
    end
  end
  
  def filename_from_url(url)
    return if url.nil?
    base = url.split(/\?/).first
    return if base.nil?
    base.split(/\//).last
  end
  
  def media_url?(url)
    if filename_from_url(url) =~ /\.(mp3|avi|mpg|mp4|flv|ogg)$/
      $1
    else
      nil
    end
  end
  
  def check_for_problem!
    code = @easy.response_code
    unless OKAY_CODES.include? code
      raise "Error: #{code} - #{HTTP_STATUS_CODES[code]}"
    end
  end

  
end


class Link
  
  attr_accessor :base, :relative, :grabber
  
  def initialize(base, relative)
    @base = base
    @relative = relative
    @grabber = Grabber.new
  end
  
  def absolute
    if relative =~ /^http/
      relative
    else
      URI.join(base, relative).to_s
    end
  end
  
  alias_method :to_s, :absolute
  alias_method :url,  :absolute
  
  def save(dest=".")
    if File.directory?(dest)
      save_to = File.join( dest, filename_from_url(url) )
    elsif File.exists?(dest)
      # TODO: Resume?
      raise "Error: #{dest} already exists."
    else
      save_to = dest
    end
    
    puts %{- "#{url}" -> "#{save_to}"...}
    # @easy.on_progress { |dl_total, dl_now, ul_total, ul_now| ... }
    
    grabber.download(url, save_to) 
    puts
  end
  
end


class Page
  
  attr_accessor :url, :grabber
  
  def initialize(url)
    @url = url
    @grabber = Grabber.new
  end

  def filename_from_url(url)
    return if url.nil?
    base = url.split(/\?/).first
    return if base.nil?
    base.split(/\//).last
  end

  def media_url?(url)
    if filename_from_url(url) =~ /\.(mp3|avi|mpg|mp4|flv|ogg)$/
      $1
    else
      nil
    end
  end
  
  def get_media_links
    doc = Nokogiri::HTML( grabber.read(url) )
    
    doc.search("a").map do |a|
      link = a["href"]
      media_url?(link) ? link : nil
    end.compact
  end

  def media_links
    @media_links ||= get_media_links
  end
  
end


GRAB_VERSION = "0.0.3"

USAGE = %{
grab v#{GRAB_VERSION}

Purpose:
  Grabs all media files!

Usage:
  $ grab <webpage that has media files on it>

}

if $0 == __FILE__

  if ARGV.size < 1
    puts USAGE
    exit 1
  end

  g = Grabber.new
  
  #g.graball('http://www.phonelosers.org/issue/014/')
  ARGV.each do |arg|
    page = Page.new(arg)
    pp page.media_links
    for link in page.media_links
      system("wget", "-c", link)
    end
  #  g.graball(arg)
  end
  
  
end
